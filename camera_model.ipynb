{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pathlib\nimport random\nimport shutil\nimport torch\nimport os\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\n%matplotlib inline\n\nfrom os import path\nfrom torchvision import transforms, datasets, models\nfrom torch import optim",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3c324f7c5502c36a7c4f4b20845647109d472b7b"
      },
      "cell_type": "code",
      "source": "os.listdir(\"../input/archive\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "29e37d575ad79f057bced6603058e204ae82ca8c"
      },
      "cell_type": "code",
      "source": "# define the transform\ntrain_transform = transforms.Compose([\n                                transforms.RandomRotation(40),\n                                transforms.RandomResizedCrop(224), # most pretrained model have this size of image\n                                transforms.RandomHorizontalFlip(),\n                                transforms.ToTensor(),\n                                transforms.Normalize([0.485, 0.456, 0.406], # Normalize by mean and std\n                                                            [0.229, 0.224, 0.225])])\n\nval_transform = transforms.Compose([\n                        transforms.RandomResizedCrop(224),\n                        transforms.ToTensor(),\n                        transforms.Normalize([0.485, 0.456, 0.406], # Normalize by mean and std\n                                                            [0.229, 0.224, 0.225])])\n# load the data\ndata_path = \"../input/archive/\"\ntrain_data = datasets.ImageFolder(data_path + \"train1\", transform = train_transform)\nval_data = datasets.ImageFolder(data_path + \"val\", transform=val_transform)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "817b284347345213400513f1dba5eb8e983bdba8"
      },
      "cell_type": "code",
      "source": "train_loader = torch.utils.data.DataLoader(train_data, batch_size=16, shuffle=True)\nval_loader = torch.utils.data.DataLoader(val_data, batch_size=16)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0946c489b5e6ff445b3a150fa4fe94e626e21b7c"
      },
      "cell_type": "code",
      "source": "dataiter = iter(train_loader)\nimages, labels = dataiter.next()\nprint(type(images))\nprint(images.shape)\nprint(labels.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "092aa32ba2c724a5c9177174339e195df479344a"
      },
      "cell_type": "code",
      "source": "def imshow(image, ax=None, normalize=True):\n    if ax is None:\n        fig, ax = plt.subplots()\n    image = image.numpy().transpose((1, 2, 0))\n\n    if normalize:\n        # if the data loader has transform.normalize\n        # undo preprocessing\n        mean = np.array([0.485, 0.456, 0.406])\n        std = np.array([0.229, 0.224, 0.225])\n        image = std * image + mean\n        image = np.clip(image, 0, 1)\n\n    ax.imshow(image)\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)\n    ax.tick_params(axis='both', length=0)\n    ax.set_xticklabels('')\n    ax.set_yticklabels('')\n    \n    return ax",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2333934d058dbc28182525b12b843b0a5bfb7767"
      },
      "cell_type": "code",
      "source": "imshow(images[1]);\nimshow(images[4]);\nimshow(images[6]);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "676fe74504a1f36e23a92dd7e3cc38ff3da0aa59"
      },
      "cell_type": "code",
      "source": "model = models.densenet201(pretrained=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "37b0d61bdb3673dc2b37e9db88d2b750558f3430"
      },
      "cell_type": "code",
      "source": "for param in model.parameters():\n    param.required_grad = False",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "38ef9fc3d71384087d432084214b84de85641c42"
      },
      "cell_type": "code",
      "source": "# change the classifier\nfrom collections import OrderedDict\n\nclassifier = nn.Sequential(OrderedDict([\n              ('fc1', nn.Linear(1920, 500)),\n              ('relu1', nn.ReLU()),\n              ('dropout1', nn.Dropout(p=0.2)),\n              ('fc2', nn.Linear(500, 256)),\n              ('relu2', nn.ReLU()),\n              ('dropout2', nn.Dropout(p=0.2)),\n              ('fc3', nn.Linear(256, 10)),\n              ('output', nn.LogSoftmax(dim=1))\n              \n]))\nmodel.classifier = classifier",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d8ca09718a9916d5e9e501b7a365dacb44b32079"
      },
      "cell_type": "code",
      "source": " #Train either on GPU or CPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1c474e9d55c62c34729a44625c2a0df73e6f560f"
      },
      "cell_type": "code",
      "source": "criterion = nn.NLLLoss()\n\noptimizer = optim.SGD(model.classifier.parameters(), lr = 0.01, momentum=0.9)\n\nmodel.to(device)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e09eeb64179e54d36a6206ed97ade0ceae279789"
      },
      "cell_type": "code",
      "source": "def train(start_epoch, num_epochs):\n    for epoch in range(start_epoch, num_epochs):\n        running_loss = 0\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n\n        else:\n            validation_loss = 0\n            accuracy = 0\n\n            with torch.no_grad():\n                model.eval()\n                for images, labels in val_loader:\n                    images, labels = images.to(device), labels.to(device)\n                    outputs = model(images)\n                    loss = criterion(outputs, labels)\n                    validation_loss += loss.item()\n\n                    ps = torch.exp(outputs)\n                    top_p, top_class = ps.topk(1, dim=1)\n                    equals = top_class == labels.view(*top_class.shape)\n                    accuracy += torch.mean(equals.type(torch.FloatTensor))\n\n            model.train()\n\n            print(\"Epoch: {}/{}.. \".format(epoch+1, num_epochs),\n                  \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n                  \"Valid Loss: {:.3f}.. \".format(validation_loss/len(val_loader)),\n                  \"Valid Accuracy: {:.3f}\".format(accuracy/len(val_loader)))\n    return epoch\n            \n    \n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "01e23f689a2ad0707133ac09a222062f6fed8b75"
      },
      "cell_type": "code",
      "source": "num_epochs = 3\nstart_epoch = 0\n\n# call the training function\nepoch = train(start_epoch, num_epochs)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cea5d6af1c67941bcfe5f8ae19fee4b20bc0a1e1"
      },
      "cell_type": "code",
      "source": "model.class_to_idx = train_data.class_to_idx",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c058d267a9c6b02cac8b569aef471430174715f3"
      },
      "cell_type": "code",
      "source": "def save_model(epoch, model.class_to_idx, model):\n    return torch.save({'epoch': epoch + 1,\n            \"state_dict\":model.state_dict(),\n           \"class_to_idx\":model.class_to_idx}, 'classifier.pth')\n\nsave_model(epoch, model.class_to_idx, model)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "58b12dc16789c555f37d5106a589c7d229113157"
      },
      "cell_type": "code",
      "source": "state_dict = torch.load(\"classifier.pth\", map_location=\"cpu\")\n\nstart_epoch = state_dict[\"epoch\"]\nnum_epochs = 8\n\n# resuming from a checkpoint\nepoch = train(start_epoch, num_epochs)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9eb107427a77e827556e4f76ff8806c754fab6f1"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}