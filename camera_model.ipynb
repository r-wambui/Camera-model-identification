{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pathlib\n",
    "import random\n",
    "import shutil\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "%matplotlib inline\n",
    "\n",
    "from os import path\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3c324f7c5502c36a7c4f4b20845647109d472b7b"
   },
   "outputs": [],
   "source": [
    "os.listdir(\"../input/archive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "29e37d575ad79f057bced6603058e204ae82ca8c"
   },
   "outputs": [],
   "source": [
    "# define the transform\n",
    "train_transform = transforms.Compose([\n",
    "                                transforms.RandomRotation(40),\n",
    "                                transforms.RandomResizedCrop(224), # most pretrained model have this size of image\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.485, 0.456, 0.406], # Normalize by mean and std\n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "                        transforms.RandomResizedCrop(224),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize([0.485, 0.456, 0.406], # Normalize by mean and std\n",
    "                                                            [0.229, 0.224, 0.225])])\n",
    "# load the data\n",
    "data_path = \"../input/archive/\"\n",
    "train_data = datasets.ImageFolder(data_path + \"train1\", transform = train_transform)\n",
    "val_data = datasets.ImageFolder(data_path + \"val\", transform=val_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "817b284347345213400513f1dba5eb8e983bdba8"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0946c489b5e6ff445b3a150fa4fe94e626e21b7c"
   },
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "092aa32ba2c724a5c9177174339e195df479344a"
   },
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, normalize=True):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "\n",
    "    if normalize:\n",
    "        # if the data loader has transform.normalize\n",
    "        # undo preprocessing\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        image = std * image + mean\n",
    "        image = np.clip(image, 0, 1)\n",
    "\n",
    "    ax.imshow(image)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.tick_params(axis='both', length=0)\n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_yticklabels('')\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2333934d058dbc28182525b12b843b0a5bfb7767"
   },
   "outputs": [],
   "source": [
    "imshow(images[1]);\n",
    "imshow(images[4]);\n",
    "imshow(images[6]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "676fe74504a1f36e23a92dd7e3cc38ff3da0aa59"
   },
   "outputs": [],
   "source": [
    "model = models.densenet201(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "37b0d61bdb3673dc2b37e9db88d2b750558f3430"
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.required_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "38ef9fc3d71384087d432084214b84de85641c42"
   },
   "outputs": [],
   "source": [
    "# change the classifier\n",
    "from collections import OrderedDict\n",
    "\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "              ('fc1', nn.Linear(1920, 500)),\n",
    "              ('relu1', nn.ReLU()),\n",
    "              ('dropout1', nn.Dropout(p=0.2)),\n",
    "              ('fc2', nn.Linear(500, 256)),\n",
    "              ('relu2', nn.ReLU()),\n",
    "              ('dropout2', nn.Dropout(p=0.2)),\n",
    "              ('fc3', nn.Linear(256, 10)),\n",
    "              ('output', nn.LogSoftmax(dim=1))\n",
    "              \n",
    "]))\n",
    "model.classifier = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d8ca09718a9916d5e9e501b7a365dacb44b32079"
   },
   "outputs": [],
   "source": [
    " #Train either on GPU or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1c474e9d55c62c34729a44625c2a0df73e6f560f"
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.classifier.parameters(), lr = 0.01, momentum=0.9)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e09eeb64179e54d36a6206ed97ade0ceae279789"
   },
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        validation_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                validation_loss += loss.item()\n",
    "                \n",
    "                ps = torch.exp(outputs)\n",
    "                top_p, top_class = ps.topk(1, dim=1)\n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(epoch+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
    "              \"Valid Loss: {:.3f}.. \".format(validation_loss/len(val_loader)),\n",
    "              \"Valid Accuracy: {:.3f}\".format(accuracy/len(val_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cea5d6af1c67941bcfe5f8ae19fee4b20bc0a1e1"
   },
   "outputs": [],
   "source": [
    "model.class_to_idx = train_data.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c058d267a9c6b02cac8b569aef471430174715f3"
   },
   "outputs": [],
   "source": [
    "torch.save({'epoch': epoch + 1,\n",
    "            \"state_dict\":model.state_dict(),\n",
    "           \"class_to_idx\":model.class_to_idx}, 'classifier.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
